{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-things-to-know-about-spacy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LahiruTjay/advanced-spacy/blob/master/10_things_to_know_about_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6McMEdn4-Bc",
        "colab_type": "text"
      },
      "source": [
        "# 10 Things to Know about spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGG3gdshJIT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68omgh6AKYWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1xK2FJ-KdO6",
        "colab_type": "code",
        "outputId": "6cb3f9d7-06de-48ef-b104-8a69062bb8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "doc = nlp(u\"Success is not final. Failure is not fatal. It is the courage to continue that counts. :( :( \")\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success is not final.\n",
            "Failure is not fatal.\n",
            "It is the courage to continue that counts.\n",
            ":( :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r61Su2x4s-yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp.make_doc(u\"This is a sentence\")   # create a Doc from raw text\n",
        "for name, proc in nlp.pipeline:             # iterate over components in order\n",
        "    doc = proc(doc)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3AbA7lH-7Rw",
        "colab_type": "code",
        "outputId": "2469036b-1988-4043-f054-4d2ebb1c69c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(nlp.pipe_names)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger', 'parser', 'ner']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIJs_YxC_iio",
        "colab_type": "code",
        "outputId": "887ff9ad-3f97-4d32-bfc9-d85aaae3075e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def my_component(doc):\n",
        "    print(\"After tokenization, this doc has {} tokens.\".format(len(doc)))\n",
        "    print(\"The part-of-speech tags are:\", [token.pos_ for token in doc])\n",
        "    if len(doc) < 10:\n",
        "        print(\"This is a pretty short document.\")\n",
        "    return doc\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(my_component, name=\"print_info\", last=True)\n",
        "print(nlp.pipe_names)  # ['tagger', 'parser', 'ner', 'print_info']\n",
        "doc = nlp(u\"This is a sentence.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger', 'parser', 'ner', 'print_info']\n",
            "After tokenization, this doc has 5 tokens.\n",
            "The part-of-speech tags are: ['DET', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
            "This is a pretty short document.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1DIg6qgwxpY",
        "colab_type": "code",
        "outputId": "08444842-9022-42a3-c787-d4b18275003d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(u\"San Francisco considers banning sidewalk delivery robots\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "\n",
        "from spacy.tokens import Span\n",
        "\n",
        "doc = nlp(u\"FB is hiring a new VP of global policy\")\n",
        "doc.ents = [Span(doc, 0, 1, label=doc.vocab.strings[u\"ORG\"])]\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "San Francisco 0 13 GPE\n",
            "FB 0 2 ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E15F6DS3lbD4",
        "colab_type": "code",
        "outputId": "95b45bd9-30df-4560-e1a8-e988e577a121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "apple = doc[0]\n",
        "print(\"Fine-grained POS tag\", apple.pos_, apple.pos)\n",
        "print(\"Coarse-grained POS tag\", apple.tag_, apple.tag)\n",
        "print(\"Word shape\", apple.shape_, apple.shape)\n",
        "print(\"Alphanumeric characters?\", apple.is_alpha)\n",
        "print(\"Punctuation mark?\", apple.is_punct)\n",
        "\n",
        "billion = doc[10]\n",
        "print(\"Digit?\", billion.is_digit)\n",
        "print(\"Like a number?\", billion.like_num)\n",
        "print(\"Like an email address?\", billion.like_email)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine-grained POS tag PROPN 96\n",
            "Coarse-grained POS tag NNP 15794550382381185553\n",
            "Word shape Xxxxx 16072095006890171862\n",
            "Alphanumeric characters? True\n",
            "Punctuation mark? False\n",
            "Digit? False\n",
            "Like a number? True\n",
            "Like an email address? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kctvTR9jBg7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a0b6add-8403-4c98-adaa-eca74e63364d"
      },
      "source": [
        "texts = [\n",
        "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
        "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
        "]\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "for doc in nlp.pipe(texts, disable=[\"tagger\", \"parser\"]):\n",
        "    # Do something with the doc here\n",
        "    print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('$9.4 million', 'MONEY'), ('the prior year', 'DATE'), ('$2.7 million', 'MONEY')]\n",
            "[('twelve billion dollars', 'MONEY'), ('1b', 'MONEY')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}